#!/usr/bin/env python3
"""
æ‰¹é‡å‡†å¤‡ ScienceBench æ•°æ®

åˆ›å»º public/ å’Œ private/ æ•°æ®ç›®å½•
"""

import sys
import argparse
from pathlib import Path
import importlib.util


# è·¯å¾„é…ç½®
COMPETITIONS_DIR = Path('/home/aiops/liufan/projects/DeepModeling/benchmarks/sciencebench/competitions')
DATA_BASE_DIR = Path('/home/aiops/liufan/projects/ScienceAgent-bench/competitions')
SCIENCEAGENT_DATASETS_DIR = Path('/home/aiops/liufan/projects/ScienceAgent-bench/benchmark/datasets')


def load_prepare_function(competition_dir: Path):
    """åŠ¨æ€åŠ è½½ prepare.py ä¸­çš„ prepare å‡½æ•°"""
    prepare_file = competition_dir / 'prepare.py'

    if not prepare_file.exists():
        print(f"âŒ prepare.py not found in {competition_dir}")
        return None

    # åŠ¨æ€åŠ è½½æ¨¡å—
    spec = importlib.util.spec_from_file_location("prepare_module", prepare_file)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)

    if not hasattr(module, 'prepare'):
        print(f"âŒ prepare() function not found in {prepare_file}")
        return None

    return module.prepare


def prepare_competition_data(comp_id: str, dataset_name: str = None) -> bool:
    """
    å‡†å¤‡å•ä¸ªæ¯”èµ›çš„æ•°æ®

    Args:
        comp_id: Competition ID (e.g., sciencebench-001-clintox-nn)
        dataset_name: Dataset directory name (auto-inferred if None)

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    print(f"\n{'='*60}")
    print(f"Preparing data for: {comp_id}")
    print(f"{'='*60}")

    # è·å–æ¯”èµ›ç›®å½•
    comp_dir = COMPETITIONS_DIR / comp_id
    if not comp_dir.exists():
        print(f"âŒ Competition directory not found: {comp_dir}")
        return False

    # æ¨æ–­æ•°æ®é›†åç§°
    if dataset_name is None:
        # ä» comp_id æå–ï¼šsciencebench-001-clintox-nn -> clintox
        parts = comp_id.split('-')
        if len(parts) >= 3:
            dataset_name = '-'.join(parts[2:])  # clintox-nn
            # å°è¯•æ‰¾åˆ°åŒ¹é…çš„æ•°æ®é›†
            possible_names = [
                dataset_name,
                dataset_name.replace('-', '_'),
                parts[2],  # ç¬¬ä¸€éƒ¨åˆ†
            ]

            for name in possible_names:
                if (SCIENCEAGENT_DATASETS_DIR / name).exists():
                    dataset_name = name
                    break
                # å°è¯• clintox (å»æ‰åç¼€)
                if (SCIENCEAGENT_DATASETS_DIR / name.split('-')[0]).exists():
                    dataset_name = name.split('-')[0]
                    break
            else:
                print(f"âš  Warning: Could not find dataset for {comp_id}")
                print(f"   Tried: {possible_names}")
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªä½œä¸ºé»˜è®¤å€¼
                dataset_name = possible_names[0]

    # åŠ è½½ prepare å‡½æ•°
    prepare_fn = load_prepare_function(comp_dir)
    if prepare_fn is None:
        return False

    source_dataset = prepare_fn.__globals__.get('SOURCE_DATASET')
    if source_dataset:
        dataset_name = source_dataset

    print(f"Dataset name: {dataset_name}")

    # è®¾ç½®è·¯å¾„
    raw_dir = SCIENCEAGENT_DATASETS_DIR / dataset_name
    data_dir = DATA_BASE_DIR / comp_id
    public_dir = data_dir / 'prepared' / 'public'
    private_dir = data_dir / 'prepared' / 'private'

    print(f"Raw data: {raw_dir}")
    print(f"Data dir: {data_dir}")

    # åˆ›å»ºæ•°æ®ç›®å½•
    public_dir.mkdir(parents=True, exist_ok=True)
    private_dir.mkdir(parents=True, exist_ok=True)
    print(f"âœ“ Created data directories")

    # è¿è¡Œ prepare
    try:
        print(f"\nğŸ“¦ Running prepare function...")
        prepare_fn(raw_dir, public_dir, private_dir)
        print(f"âœ… Data preparation completed!")

        # éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶
        public_files = list(public_dir.glob('*'))
        private_files = list(private_dir.glob('*'))

        print(f"\nğŸ“Š Generated files:")
        print(f"  Public:  {len(public_files)} files")
        for f in public_files:
            print(f"    - {f.name}")
        print(f"  Private: {len(private_files)} files")
        for f in private_files:
            print(f"    - {f.name}")

        return True

    except Exception as e:
        print(f"âŒ Error during data preparation: {e}")
        import traceback
        traceback.print_exc()
        return False


def list_competitions():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¯”èµ›"""
    if not COMPETITIONS_DIR.exists():
        print(f"âŒ Competitions directory not found: {COMPETITIONS_DIR}")
        return []

    competitions = sorted([d.name for d in COMPETITIONS_DIR.iterdir() if d.is_dir()])

    print(f"\n{'='*60}")
    print(f"Available Competitions ({len(competitions)})")
    print(f"{'='*60}\n")

    for comp_id in competitions:
        # æ£€æŸ¥æ˜¯å¦å·²å‡†å¤‡æ•°æ®
        data_dir = DATA_BASE_DIR / comp_id / 'prepared'
        status = "âœ…" if data_dir.exists() and any(data_dir.glob('*/*')) else "âŒ"
        print(f"{status} {comp_id}")

    print()
    return competitions


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='Prepare data for ScienceBench competitions'
    )
    parser.add_argument(
        '--competitions',
        nargs='+',
        help='Competition IDs to prepare'
    )
    parser.add_argument(
        '--all',
        action='store_true',
        help='Prepare all competitions'
    )
    parser.add_argument(
        '--list',
        action='store_true',
        help='List all available competitions'
    )
    parser.add_argument(
        '--dataset-name',
        type=str,
        help='Override dataset name'
    )

    args = parser.parse_args()

    # åˆ—å‡ºæ¯”èµ›
    if args.list:
        list_competitions()
        return

    # ç¡®å®šè¦å‡†å¤‡çš„æ¯”èµ›
    if args.competitions:
        comp_ids = args.competitions
    elif args.all:
        comp_ids = [d.name for d in COMPETITIONS_DIR.iterdir() if d.is_dir()]
    else:
        print("âŒ Please specify --competitions, --all, or --list")
        parser.print_help()
        return

    print(f"\nğŸš€ Preparing data for {len(comp_ids)} competition(s)...\n")

    # å‡†å¤‡æ•°æ®
    success_count = 0
    failed_comps = []

    for comp_id in comp_ids:
        success = prepare_competition_data(comp_id, args.dataset_name)

        if success:
            success_count += 1
        else:
            failed_comps.append(comp_id)

    # æ€»ç»“
    print(f"\n{'='*60}")
    print(f"Data Preparation Summary")
    print(f"{'='*60}")
    print(f"âœ… Success: {success_count}/{len(comp_ids)}")
    if failed_comps:
        print(f"âŒ Failed: {len(failed_comps)}")
        print(f"   Competitions: {failed_comps}")
    print(f"{'='*60}\n")


if __name__ == '__main__':
    main()
