<a name="readme-top"></a>

<div align="center">
  <h1 align="center">DeepModeling: Agentic LLM for Autonomous Problem Solving</h1>
  <h3>Data Science â€¢ Mathematical Modeling â€¢ Scientific Discovery â€¢ Engineering</h3>
</div>

<div align="center">
  <a href="#"><img src="https://img.shields.io/badge/Python-3.11+-blue.svg?logo=python&logoColor=white" alt="Python"></a>
  <a href="#"><img src="https://img.shields.io/badge/Framework-Agentic%20LLM-orange.svg" alt="Framework"></a>
  <a href="#"><img src="https://img.shields.io/badge/Benchmarks-1,851%20Problems-green.svg" alt="Benchmark"></a>
  <a href="#quick-start"><img src="https://img.shields.io/badge/Get%20Started-Quick%20Start-red.svg" alt="Quick Start"></a>
</div>

---

**DeepModeling** is an agentic LLM framework that autonomously solves complex problems across **four major domains**:

### ğŸ¯ Four Pillars of Autonomous Problem Solving

| Domain | Problems | Description |
|--------|----------|-------------|
| ğŸ“Š **Data Science** | 349 | Kaggle-style ML competitions, predictive modeling, multi-modal analysis |
| ğŸ“ **Mathematical Modeling** | 1,296 | Operations research, optimization, linear programming, differential equations |
| ğŸ”¬ **Scientific Discovery** | 104 | Computational chemistry, materials science, physics simulations, drug discovery |
| âš™ï¸ **Engineering** | 102 | Industrial optimization, process design, systems engineering |
| **Total** | **1,851** | Comprehensive autonomous problem-solving suite |

### âœ¨ Core Capabilities

- ğŸ¯ **Full Autonomy**: Complete end-to-end automation from problem analysis to solution
- ğŸ”„ **Iterative Discovery**: Self-correcting workflow from hypothesis to validated conclusions
- ğŸ§  **Scientific Reasoning**: Structured XML-tag-based reasoning following scientific method
- ğŸ¨ **Multi-Modal Support**: Handles any data modality (images, time series, tabular, text) and format (CSV, JSON, Parquet, HDF5, etc.)
- ğŸš€ **Production Ready**: Flexible data storage, external storage support, extensible architecture

<span id='table-of-contents'/>

## ğŸ“‘ Table of Contents

* <a href='#news'>ğŸ”¥ News</a>
* <a href='#four-domains'>ğŸ¯ Four Domain Overview</a>
  * <a href='#data-science'>ğŸ“Š Data Science</a>
  * <a href='#mathematical-modeling'>ğŸ“ Mathematical Modeling</a>
  * <a href='#scientific-discovery'>ğŸ”¬ Scientific Discovery</a>
  * <a href='#engineering'>âš™ï¸ Engineering</a>
* <a href='#key-features'>âœ¨ Key Features</a>
* <a href='#architecture'>ğŸ—ï¸ Architecture</a>
* <a href='#quick-start'>âš¡ Quick Start</a>
  * <a href='#installation'>Installation</a>
  * <a href='#running-benchmarks'>Running Benchmarks</a>
* <a href='#benchmarks'>ğŸ“Š Benchmark Details</a>
* <a href='#data-storage'>ğŸ’¾ Data Storage Architecture</a>
* <a href='#workflow'>ğŸ”¬ Scientific Workflow</a>
* <a href='#documentation'>ğŸ“– Documentation</a>
* <a href='#citation'>ğŸŒŸ Citation</a>

<span id='news'/>

## ğŸ”¥ News

<div class="scrollable">
  <ul>
    <li><strong>[2025.11]</strong>: ğŸ¯ <b>Four-Domain Framework</b> - Unified platform for Data Science, Mathematical Modeling, Scientific Discovery, and Engineering with 1,851 benchmark problems!</li>
    <li><strong>[2025.11]</strong>: âš™ï¸ <b>Engineering Benchmark</b> - 102 industrial engineering problems including process optimization and systems design!</li>
    <li><strong>[2025.11]</strong>: ğŸ”¬ <b>Scientific Discovery Benchmark</b> - 104 computational science problems spanning chemistry, materials, and physics!</li>
    <li><strong>[2025.11]</strong>: ğŸ“Š <b>Data Science Benchmark</b> - 349 Kaggle-style ML competitions with multi-modal support!</li>
    <li><strong>[2025.11]</strong>: ğŸ“ <b>Mathematical Modeling Benchmark</b> - 1,296 optimization and operations research problems!</li>
    <li><strong>[2025.11]</strong>: ğŸ¨ <b>Multi-Modal Data Support</b> - Full support for any data modality (images, time series, tabular, text) and format!</li>
    <li><strong>[2025.11]</strong>: ğŸ‰ <b>Registry-Data Separation Architecture</b> - Supports external data storage for large-scale datasets!</li>
    <li><strong>[2025.11]</strong>: ğŸ§  <b>Scientific Workflow</b> - Autonomous problem-solving using XML-structured reasoning following the scientific method!</li>
  </ul>
</div>

<span id='four-domains'/>

## ğŸ¯ Four Domain Overview

DeepModeling provides comprehensive benchmark suites across four fundamental domains of computational problem-solving:

<span id='data-science'/>

### ğŸ“Š 1. Data Science (349 Problems)

**Kaggle-Style Machine Learning Competitions**

The Data Science domain covers end-to-end machine learning workflows, from data preprocessing to model deployment:

**Core Areas:**
- **Supervised Learning**: Classification, regression, and ranking tasks across all data modalities
- **Time Series Forecasting**: Stock prediction, demand forecasting, anomaly detection
- **Computer Vision**: Image classification, object detection, segmentation
- **Natural Language Processing**: Text classification, sentiment analysis, named entity recognition
- **Feature Engineering**: Automated preprocessing, dimensionality reduction, feature selection
- **Model Selection**: Hyperparameter tuning, ensemble methods, cross-validation

**Data Modalities:**
- ğŸ“Š Tabular data (CSV, Parquet, Excel)
- ğŸ–¼ï¸ Images (PNG, JPG, TIFF, medical imaging)
- ğŸ“ Text (JSON, TXT, documents)
- ğŸ“ˆ Time series (sensor data, stock prices, weather)
- ğŸµ Audio and ğŸ¥ Video

**Example Tasks:**
- Titanic survival prediction
- House price regression
- Digit recognition (MNIST, CIFAR)
- Sentiment analysis on reviews
- Multi-modal image-text classification

<span id='mathematical-modeling'/>

### ğŸ“ 2. Mathematical Modeling (1,296 Problems)

**Optimization, Operations Research & Differential Equations**

The Mathematical Modeling domain focuses on quantitative analysis and optimization:

**Core Areas:**
- **Linear Programming**: Resource allocation, production planning, blending problems
- **Operations Research**: Scheduling, assignment, transportation, network flow
- **Business Analytics**: Profit maximization, cost minimization, supply chain optimization
- **Differential Equations**: Dynamic systems, population models, physics simulations

**Problem Categories:**
- **BWOR** (82): Business and Operations Research
- **IndustryOR** (100): Industrial Operations Research
- **Easy LP** (652): Linear programming foundations
- **Complex LP** (211): Advanced optimization problems
- **ODE** (346): Ordinary differential equations
- **Others** (105): Mixed problem types

**Example Tasks:**
- Candy production optimization (maximize profit under constraints)
- Transportation network design
- Inventory management
- Portfolio optimization
- Population growth modeling

<span id='scientific-discovery'/>

### ğŸ”¬ 3. Scientific Discovery (104 Problems)

**Computational Science & Research**

The Scientific Discovery domain tackles cutting-edge research problems in natural sciences:

**Core Areas:**
- **Computational Chemistry**: Drug toxicity prediction, molecular property estimation
- **Materials Science**: Material property prediction, feature selection, bulk modulus estimation
- **Physics Simulations**: Electronic structure calculations, quantum mechanics
- **Data Analysis**: Scientific data visualization, correlation analysis, factor identification

**Key Capabilities:**
- Deep learning for scientific data (molecular SMILES, crystal structures)
- Multi-task prediction models
- Physics-informed neural networks
- Scientific visualization and exploratory analysis

**Example Tasks:**
- ClinTox: Drug toxicity and FDA approval prediction
- Material feature selection for property prediction
- Bulk modulus prediction from crystal structures
- Electronic structure calculation (Elk dataset)
- Scientific data visualization and pattern discovery

<span id='engineering'/>

### âš™ï¸ 4. Engineering (102 Problems)

**Industrial Process Optimization & Systems Design**

The Engineering domain addresses real-world industrial and systems engineering challenges:

**Core Areas:**
- **Process Optimization**: Manufacturing efficiency, production scheduling
- **Systems Engineering**: Complex system design and integration
- **Industrial Automation**: Workflow optimization, resource management
- **Quality Control**: Defect detection, process monitoring

**Problem Types:**
- Industrial production planning
- Manufacturing resource allocation
- Process parameter optimization
- System performance analysis
- Engineering constraint satisfaction

**Example Tasks:**
- Industrial production scheduling
- Manufacturing cost minimization
- Process efficiency optimization
- Multi-stage production planning
- Quality assurance workflows

---

<span id='key-features'/>

## âœ¨ Key Features

### ğŸ”¬ Scientific Method Workflow

The framework implements a complete scientific method cycle with structured XML-based reasoning:

```
Phenomenon â†’ Hypothesis â†’ Model â†’ Experiment â†’ Observation â†’ Inference â†’ Conclusion
     â†‘                                                              â†“
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        (Iterates until solved)
```

**Core Capabilities:**
- ğŸ“š **Phenomenon Analysis**: Systematically analyzes problem statements and data
- ğŸ’¡ **Hypothesis Generation**: Formulates testable hypotheses based on observations
- ğŸ§ª **Model Development**: Designs and implements mathematical/computational models
- ğŸ”¬ **Experimentation**: Executes code and collects empirical results
- ğŸ“Š **Observation Processing**: Interprets outputs and identifies patterns
- ğŸ¯ **Inference & Conclusion**: Draws conclusions and validates against ground truth

### ğŸ”’ Ground Truth Protection

- **Public Data** (given to LLM): Problem statement WITHOUT answers
- **Private Data** (for grading): Ground truth answers stored separately
- **Raw Data**: Complete original problem for reference
- **Answer Sanitization**: Automatic removal of answers from public problem statements

### ğŸ¨ Multi-Modal Data Support

The framework handles **any data modality** and **any file format**:

**Supported Data Modalities:**
- ğŸ“Š **Tabular Data**: Structured data with rows and columns (CSV, Excel, Parquet, Feather, HDF5)
- ğŸ“ˆ **Time Series**: Sequential temporal data (stock prices, sensor readings, weather data)
- ğŸ–¼ï¸ **Images**: Computer vision tasks (PNG, JPG, TIFF, medical imaging formats)
- ğŸ“ **Text**: Natural language processing (TXT, JSON, XML, Markdown)
- ğŸµ **Audio**: Sound and speech data (WAV, MP3, FLAC)
- ğŸ¥ **Video**: Sequential visual data (MP4, AVI)
- ğŸ”¢ **Numeric Arrays**: Multi-dimensional data (NumPy arrays, tensors)

**Supported File Formats:**
- **Data Formats**: CSV, JSON, Parquet, Feather, HDF5, Pickle, Excel (XLSX, XLS)
- **Image Formats**: PNG, JPG, JPEG, TIFF, BMP, GIF, SVG
- **Scientific Formats**: NetCDF, MATLAB (.mat), R data (.rds)
- **Database Formats**: SQLite, PostgreSQL dumps, MongoDB exports
- **Compressed Formats**: ZIP, TAR, GZ, BZ2

**Automatic Format Detection:**
The framework automatically detects and handles different data formats, preprocessing pipelines, and modality-specific operations without manual configuration.

### ğŸ“Š Comprehensive Benchmark Suite

**Mathematical Modeling Benchmarks (1,394 problems):**

| Dataset | Problems | Description |
|---------|----------|-------------|
| **BWOR** | 82 | Business and Operations Research problems |
| **IndustryOR** | 100 | Industrial Operations Research tasks |
| **MaMo Easy LP** | 652 | Easy linear programming problems |
| **MaMo Complex LP** | 211 | Complex linear programming tasks |
| **MaMo ODE** | 346 | Ordinary Differential Equation problems |
| **Original** | 3 | Hand-crafted benchmark tasks |
| **Subtotal** | **1,394** | Comprehensive mathematical modeling suite |

**Data Science Benchmarks (MLE-Bench):**

| Category | Description | Tasks | Data Modalities |
|----------|-------------|-------|-----------------|
| **Kaggle Competitions** | Real-world machine learning challenges | Classification, Regression, Time Series | Tabular, Images, Text, Time Series |
| **Data Analysis** | Exploratory data analysis and visualization | Statistical analysis, Feature engineering | All modalities supported |
| **Model Development** | End-to-end ML pipeline creation | Training, Validation, Prediction | Multi-modal pipelines |
| **Computer Vision** | Image and video processing | Object detection, Segmentation, Classification | Images, Video |
| **Natural Language** | Text understanding and generation | Text classification, Sentiment, NER | Text, Documents |
| **Time Series** | Temporal pattern recognition | Forecasting, Anomaly detection | Sequential data |
| **Evaluation** | Automated scoring against ground truth | Accuracy, F1, RMSE, AUC, IoU, BLEU | Modality-specific metrics |

### ğŸ¯ Automatic Evaluation

The framework automatically detects submission tags and evaluates solutions:
- `@profit[value]` - For profit maximization problems
- `@cost[value]` - For cost minimization problems
- `@value[value]` - For general numeric solutions

**Evaluation Features:**
- Exact match checker with tolerance (Â±1e-2)
- Consistent grading across all competitions
- CSV-based submission format
- Automated metrics and reporting

<span id='architecture'/>

## ğŸ—ï¸ Architecture

```
DeepModeling/
â”œâ”€â”€ benchmarks/                 # Registry (metadata, ~50MB)
â”‚   â”‚
â”‚   â”œâ”€â”€ mlebench/               # ğŸ“Š Data Science (349 competitions)
â”‚   â”‚   â””â”€â”€ competitions/
â”‚   â”‚       â””â”€â”€ [competition-id]/
â”‚   â”‚           â”œâ”€â”€ description.md        # Problem statement
â”‚   â”‚           â”œâ”€â”€ prepare.py           # Data preparation
â”‚   â”‚           â”œâ”€â”€ grade.py             # Scoring function
â”‚   â”‚           â””â”€â”€ metadata.json        # Competition config
â”‚   â”‚
â”‚   â”œâ”€â”€ mathmodelingbench/      # ğŸ“ Mathematical Modeling (1,296 competitions)
â”‚   â”‚   â””â”€â”€ competitions/
â”‚   â”‚       â”œâ”€â”€ bwor-*/         # Business OR (82)
â”‚   â”‚       â”œâ”€â”€ industry-*/     # Industry OR (100)
â”‚   â”‚       â”œâ”€â”€ mamo-easy-*/    # Easy LP (652)
â”‚   â”‚       â”œâ”€â”€ mamo-complex-*/ # Complex LP (211)
â”‚   â”‚       â”œâ”€â”€ mamo-ode-*/     # ODE (346)
â”‚   â”‚       â””â”€â”€ others-*/       # Others (105)
â”‚   â”‚
â”‚   â”œâ”€â”€ sciencebench/           # ğŸ”¬ Scientific Discovery (104 competitions)
â”‚   â”‚   â””â”€â”€ competitions/
â”‚   â”‚       â””â”€â”€ sciencebench-*/
â”‚   â”‚           â”œâ”€â”€ description.md        # Research problem
â”‚   â”‚           â”œâ”€â”€ prepare.py           # Data prep
â”‚   â”‚           â”œâ”€â”€ grade.py             # Evaluation
â”‚   â”‚           â””â”€â”€ metadata.json        # Config
â”‚   â”‚
â”‚   â””â”€â”€ engineeringbench/       # âš™ï¸ Engineering (102 competitions)
â”‚       â””â”€â”€ competitions/
â”‚           â””â”€â”€ industry-*/
â”‚               â”œâ”€â”€ description.md        # Engineering problem
â”‚               â”œâ”€â”€ prepare.py           # Setup
â”‚               â”œâ”€â”€ grade.py             # Grading
â”‚               â””â”€â”€ metadata.json        # Config
â”‚
â”œâ”€â”€ data/                       # Actual data (can be external)
â”‚   â”‚
â”‚   â”œâ”€â”€ mlebench/               # ğŸ“Š Data Science data
â”‚   â”‚   â””â”€â”€ competitions/
â”‚   â”‚       â””â”€â”€ [competition-id]/
â”‚   â”‚           â”œâ”€â”€ raw/                # Original Kaggle data
â”‚   â”‚           â””â”€â”€ prepared/
â”‚   â”‚               â”œâ”€â”€ public/         # Train/test for LLM
â”‚   â”‚               â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚               â”‚   â”œâ”€â”€ test.csv
â”‚   â”‚               â”‚   â””â”€â”€ sample_submission.csv
â”‚   â”‚               â””â”€â”€ private/        # Ground truth
â”‚   â”‚                   â””â”€â”€ solution.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ mathmodeling-bench/     # ğŸ“ Mathematical Modeling data
â”‚   â”‚   â””â”€â”€ competitions/
â”‚   â”‚       â””â”€â”€ [competition-id]/
â”‚   â”‚           â”œâ”€â”€ raw/
â”‚   â”‚           â”‚   â””â”€â”€ problem.json           # Original with answer
â”‚   â”‚           â””â”€â”€ prepared/
â”‚   â”‚               â”œâ”€â”€ public/
â”‚   â”‚               â”‚   â”œâ”€â”€ problem.json       # WITHOUT answer
â”‚   â”‚               â”‚   â””â”€â”€ sample_submission.csv
â”‚   â”‚               â””â”€â”€ private/
â”‚   â”‚                   â””â”€â”€ answer.csv         # Ground truth
â”‚   â”‚
â”‚   â”œâ”€â”€ sciencebench/           # ğŸ”¬ Scientific Discovery data
â”‚   â”‚   â””â”€â”€ competitions/
â”‚   â”‚       â””â”€â”€ [competition-id]/
â”‚   â”‚           â”œâ”€â”€ raw/                # Original research data
â”‚   â”‚           â””â”€â”€ prepared/
â”‚   â”‚               â”œâ”€â”€ public/         # Dataset for LLM
â”‚   â”‚               â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚               â”‚   â”œâ”€â”€ test.csv
â”‚   â”‚               â”‚   â””â”€â”€ sample_submission.csv
â”‚   â”‚               â””â”€â”€ private/        # Expected results
â”‚   â”‚                   â””â”€â”€ solution.csv
â”‚   â”‚
â”‚   â””â”€â”€ engineeringbench/       # âš™ï¸ Engineering data
â”‚       â””â”€â”€ competitions/
â”‚           â””â”€â”€ [competition-id]/
â”‚               â”œâ”€â”€ raw/
â”‚               â”‚   â””â”€â”€ problem.json           # Original problem
â”‚               â””â”€â”€ prepared/
â”‚                   â”œâ”€â”€ public/
â”‚                   â”‚   â”œâ”€â”€ problem.json       # Problem statement
â”‚                   â”‚   â””â”€â”€ sample_submission.csv
â”‚                   â””â”€â”€ private/
â”‚                       â””â”€â”€ answer.csv         # Ground truth
â”‚
â”œâ”€â”€ modeling/                   # Core framework
â”‚   â”œâ”€â”€ workflows/              # Scientific workflow
â”‚   â”œâ”€â”€ services/               # LLM, Sandbox, Workspace
â”‚   â”œâ”€â”€ operators/              # Code generation, execution
â”‚   â””â”€â”€ benchmark/              # Benchmark integration
â”‚       â”œâ”€â”€ mle.py             # ğŸ“Š Data Science (MLE-Bench)
â”‚       â”œâ”€â”€ mathmodeling.py    # ğŸ“ Mathematical Modeling
â”‚       â”œâ”€â”€ science.py         # ğŸ”¬ Scientific Discovery
â”‚       â””â”€â”€ engineering.py     # âš™ï¸ Engineering
â”‚
â”œâ”€â”€ examples/                   # Tools and examples
â”œâ”€â”€ docs/                       # Documentation (14 files)
â”œâ”€â”€ main.py                     # Entry point
â””â”€â”€ config.yaml                 # Competition configuration
```

<span id='quick-start'/>

## âš¡ Quick Start

<span id='installation'/>

### Installation

```bash
# Clone the repository
git clone https://github.com/your-org/DeepModeling.git
cd DeepModeling

# Create and activate virtual environment
python -m venv deepmodeling-env
source deepmodeling-env/bin/activate  # On Windows: deepmodeling-env\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### API Keys Setup

Create a `.env` file with your API credentials:

```bash
cp .env.example .env
# Edit .env and add your API keys
```

Example `.env` configuration:

```bash
# LLM Provider Configuration
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key

# Optional: Custom API endpoints
OPENAI_API_BASE=https://api.openai.com/v1
```

<span id='running-benchmarks'/>

### Running Benchmarks

DeepModeling supports all four domains with a unified interface:

#### ğŸ“Š Data Science Tasks

```bash
# Single Kaggle-style competition
python main.py --workflow scientific --benchmark mle \
  --data-dir ./data/mlebench \
  --llm-model gpt-4o-mini \
  --task spaceship-titanic

# Batch evaluation (all 349 tasks)
python main.py --workflow scientific --benchmark mle \
  --data-dir ./data/mlebench \
  --llm-model gpt-4o-mini
```

#### ğŸ“ Mathematical Modeling Tasks

```bash
# Single optimization problem
python main.py --workflow scientific --benchmark mathmodeling \
  --data-dir ./data/mathmodeling-bench \
  --llm-model gpt-4o-mini \
  --task bwor-0

# Batch evaluation (all 1,296 tasks)
python main.py --workflow scientific --benchmark mathmodeling \
  --data-dir ./data/mathmodeling-bench \
  --llm-model gpt-4o-mini
```

#### ğŸ”¬ Scientific Discovery Tasks

```bash
# Single research problem
python main.py --workflow scientific --benchmark science \
  --data-dir ./data/sciencebench \
  --llm-model gpt-4o-mini \
  --task sciencebench-001-clintox-nn

# Batch evaluation (all 104 tasks)
python main.py --workflow scientific --benchmark science \
  --data-dir ./data/sciencebench \
  --llm-model gpt-4o-mini
```

#### âš™ï¸ Engineering Tasks

```bash
# Single engineering problem
python main.py --workflow scientific --benchmark engineering \
  --data-dir ./data/engineeringbench \
  --llm-model gpt-4o-mini \
  --task industry-0

# Batch evaluation (all 102 tasks)
python main.py --workflow scientific --benchmark engineering \
  --data-dir ./data/engineeringbench \
  --llm-model gpt-4o-mini
```

#### ğŸ’¾ External Data Storage

All domains support external storage for large datasets:

```bash
# Using external drive for any domain
python main.py --workflow scientific --benchmark [mle|mathmodeling|science|engineering] \
  --data-dir /mnt/external_drive/data \
  --llm-model gpt-4o-mini \
  --task [task-id]
```

<span id='benchmarks'/>

## ğŸ“Š Benchmark Details

### Complete Dataset Statistics

The framework provides **1,851 benchmark problems** across **four major domains**:

| Domain | Total | Subcategories | Description |
|--------|-------|---------------|-------------|
| **ğŸ“Š Data Science** | **349** | MLE-Bench competitions | Kaggle-style ML tasks across all modalities |
| **ğŸ“ Mathematical Modeling** | **1,296** | BWOR (82), Industry OR (100), Easy LP (652), Complex LP (211), ODE (346), Others (105) | Optimization and differential equations |
| **ğŸ”¬ Scientific Discovery** | **104** | Chemistry, Materials, Physics | Computational science research |
| **âš™ï¸ Engineering** | **102** | Industrial problems | Process optimization and systems design |
| **Total** | **1,851** | 4 domains, 10+ subcategories | Comprehensive autonomous solving suite |

### Domain-Specific Breakdown

#### 1. Data Science Benchmarks (349 Problems)

**MLE-Bench**: Kaggle-style machine learning competitions

| Category | Tasks | Data Modalities |
|----------|-------|-----------------|
| Supervised Learning | Classification, Regression, Ranking | Tabular, Images, Text |
| Time Series | Forecasting, Anomaly Detection | Sequential data, Stock prices, Weather |
| Computer Vision | Image Classification, Object Detection, Segmentation | PNG, JPG, DICOM, TIFF |
| Natural Language | Text Classification, Sentiment, NER | Text, JSON, Documents |
| Multi-Modal | Image-Text, Audio-Visual | Combined modalities |
| Evaluation | Accuracy, F1, RMSE, AUC, IoU, BLEU | Modality-specific metrics |

#### 2. Mathematical Modeling Benchmarks (1,296 Problems)

| Dataset | Problems | Type | Description |
|---------|----------|------|-------------|
| **Easy LP** | 652 | Linear Programming | Foundation optimization problems |
| **ODE** | 346 | Differential Equations | Dynamic systems, physics models |
| **Complex LP** | 211 | Advanced Optimization | Complex constraint systems |
| **IndustryOR** | 100 | Operations Research | Industrial scheduling, assignment |
| **BWOR** | 82 | Business OR | Profit/cost optimization |
| **Others** | 105 | Mixed | Diverse problem types |
| **Subtotal** | **1,296** | | Comprehensive mathematical suite |

#### 3. Scientific Discovery Benchmarks (104 Problems)

| Area | Example Tasks | Methods |
|------|---------------|---------|
| **Computational Chemistry** | Drug toxicity (ClinTox), Molecular properties | Deep learning, Multi-task models |
| **Materials Science** | Bulk modulus prediction, Feature selection | Neural networks, Regression |
| **Physics** | Electronic structure (Elk), Simulations | Physics-informed NNs |
| **Data Analysis** | Visualization, Correlation analysis | Exploratory analysis, Statistics |

#### 4. Engineering Benchmarks (102 Problems)

| Category | Problem Count | Focus Areas |
|----------|---------------|-------------|
| **Industrial Optimization** | ~40 | Production scheduling, Resource allocation |
| **Process Design** | ~30 | Manufacturing efficiency, Parameter tuning |
| **Systems Engineering** | ~20 | Complex system integration |
| **Quality & Automation** | ~12 | Process monitoring, Workflow optimization |

### Problem Format

**Mathematical Modeling Problems:**

```json
{
  "id": "competition-id",
  "en_question": "English problem statement...",
  "cn_question": "ä¸­æ–‡é—®é¢˜æè¿°...",
  "difficulty": "Medium"
}
```

**Submission Format:**
```csv
id,answer
0,@profit[5450]
```

**Data Science Problems (MLE-Bench):**

Each competition provides task-specific data in appropriate formats:

**Tabular Data Tasks:**
- **train.csv**: Training data with features and labels
- **test.csv**: Test data with features only
- **sample_submission.csv**: Expected submission format
- **description.md**: Problem statement and evaluation metric

**Computer Vision Tasks:**
- **train/**: Directory with training images (PNG, JPG, etc.)
- **test/**: Directory with test images
- **train_labels.csv**: Image IDs and labels
- **sample_submission.csv**: Expected prediction format

**Time Series Tasks:**
- **train.csv** or **train.parquet**: Historical time series data
- **test.csv**: Future timestamps to predict
- **sample_submission.csv**: Forecast submission format

**NLP Tasks:**
- **train.json** or **train.csv**: Text data with labels
- **test.json**: Text samples for prediction
- **sample_submission.csv**: Text classification results

**Multi-Modal Tasks:**
- **images/**: Image directory
- **text_data.csv**: Associated text features
- **metadata.json**: Additional context
- **sample_submission.csv**: Multi-modal predictions

**Submission Format (varies by modality):**
```csv
# Tabular/Classification
id,prediction
1,0.85
2,0.32

# Computer Vision (multi-class)
image_id,class_0,class_1,class_2
img_001,0.1,0.7,0.2

# Time Series (forecast)
timestamp,value
2024-01-01,123.45
2024-01-02,124.67
```

### Adding Custom Datasets

Use the batch conversion tool:

```bash
python batch_convert_datasets.py \
  --dataset-file /path/to/your/dataset.json \
  --registry-root ./benchmarks/mathmodelingbench/competitions \
  --data-root ./data/mathmodeling-bench/competitions \
  --competition-prefix my-dataset
```

<span id='data-storage'/>

## ğŸ’¾ Data Storage Architecture

The framework uses a **registry-data separation** design for flexible storage:

### Registry (Small, ~20KB per competition)
- **Location**: `benchmarks/mathmodelingbench/competitions/` (in project)
- **Contents**: config.yaml, grade.py, prepare.py, description.md
- **Purpose**: Metadata and evaluation logic
- **Size**: ~30MB total (can stay in Git repository)

### Data (Large, can be GB+)
- **Location**: User-specified via `--data-dir` parameter
- **Contents**: raw/, prepared/public/, prepared/private/ directories
- **Purpose**: Actual problem data and ground truth
- **Size**: Can be stored on external storage (network drives, cloud storage, etc.)

### Benefits

âœ… **Flexible Storage**: Data can be anywhere (local, external, network, cloud)
âœ… **Lightweight Repository**: Git repo only contains ~30MB of registry files
âœ… **Shared Data**: Multiple projects can share the same data directory
âœ… **CI/CD Friendly**: No need to download large datasets for testing
âœ… **Cost Optimization**: Large data on cheaper storage, registry on SSD

<span id='workflow'/>

## ğŸ”¬ Scientific Workflow

The framework implements a rigorous scientific method with XML-structured reasoning across **both mathematical modeling and data science tasks**:

### Example 1: Mathematical Modeling

1. **ğŸ“š Phenomenon Analysis**
   ```xml
   <Phenomenon>
   Analyzing the candy production optimization problem...
   - Three raw materials: A, B, C
   - Three candy brands: X, Y, Z
   - Constraints: composition ratios, monthly limits
   - Objective: Maximize profit
   </Phenomenon>
   ```

2. **ğŸ’¡ Hypothesis Formulation**
   ```xml
   <Hypothesis>
   This is a linear programming problem. We can formulate:
   - Decision variables: kg of each candy brand
   - Objective function: Revenue - Cost
   - Constraints: Material limits, composition requirements
   </Hypothesis>
   ```

3. **ğŸ§ª Model Development**
   ```xml
   <Model>
   Mathematical formulation:
   max: 3.40*X + 2.85*Y + 2.25*Z - (material costs)
   s.t.: composition constraints, material limits
   </Model>
   ```

4. **ğŸ”¬ Experimentation**
   ```xml
   <Experiment>
   Implementing solution using PuLP/SciPy...
   [Code generation and execution]
   </Experiment>
   ```

5. **ğŸ“Š Observation & Analysis**
   ```xml
   <Observation>
   Solution found: X=2000kg, Y=1500kg, Z=800kg
   Profit: $5,450
   All constraints satisfied
   </Observation>
   ```

6. **ğŸ¯ Conclusion**
   ```xml
   <Conclusion>
   Optimal solution achieved. Submitting answer: @profit[5450]
   </Conclusion>
   ```

### Example 2: Data Science (Kaggle Competition)

1. **ğŸ“š Phenomenon Analysis**
   ```xml
   <Phenomenon>
   Analyzing the Titanic survival prediction task...
   - Training data: 891 passengers with features and survival labels
   - Test data: 418 passengers, need to predict survival
   - Features: Age, Sex, Passenger Class, Fare, etc.
   - Objective: Maximize prediction accuracy
   </Phenomenon>
   ```

2. **ğŸ’¡ Hypothesis Formulation**
   ```xml
   <Hypothesis>
   This is a binary classification problem. Key insights:
   - Survival likely correlated with passenger class and gender
   - Age and fare may indicate socioeconomic status
   - Missing values in Age need imputation
   - Can use ensemble methods (Random Forest, XGBoost)
   </Hypothesis>
   ```

3. **ğŸ§ª Model Development**
   ```xml
   <Model>
   Pipeline design:
   1. Data preprocessing: handle missing values, encode categoricals
   2. Feature engineering: create family_size, title from name
   3. Model: Random Forest Classifier with cross-validation
   4. Hyperparameter tuning: GridSearchCV
   </Model>
   ```

4. **ğŸ”¬ Experimentation**
   ```xml
   <Experiment>
   Implementing ML pipeline using scikit-learn...
   - Preprocessing: SimpleImputer, OneHotEncoder
   - Model: RandomForestClassifier(n_estimators=100)
   - Validation: 5-fold cross-validation
   [Code generation and execution]
   </Experiment>
   ```

5. **ğŸ“Š Observation & Analysis**
   ```xml
   <Observation>
   Cross-validation accuracy: 82.3%
   Feature importance: Sex (0.31), Pclass (0.24), Fare (0.18)
   Predictions generated for 418 test samples
   Submission file created successfully
   </Observation>
   ```

6. **ğŸ¯ Conclusion**
   ```xml
   <Conclusion>
   Model achieved good validation performance.
   Submitting predictions to competition.
   </Conclusion>
   ```

### Adaptive Iterations

The workflow automatically iterates based on:
- âŒ **Code Errors**: Fixes syntax, logic, or runtime errors
- âš ï¸ **Failed Tests**: Adjusts model based on test failures
- ğŸ“‰ **Poor Results**: Refines approach if solution is suboptimal
- âœ… **Success**: Terminates when valid solution is found

<span id='documentation'/>

## ğŸ“– Documentation

Detailed documentation is available in the [`docs/`](docs/) directory:

- **[QUICK_START_SCIENTIFIC.md](QUICK_START_SCIENTIFIC.md)** - Scientific workflow quick start
- **[docs/SCIENTIFIC_WORKFLOW_IMPLEMENTATION.md](docs/SCIENTIFIC_WORKFLOW_IMPLEMENTATION.md)** - Implementation details
- **[docs/ADAPTIVE_ITERATIONS_IMPLEMENTATION.md](docs/ADAPTIVE_ITERATIONS_IMPLEMENTATION.md)** - Adaptive iterations guide
- **[docs/README.md](docs/README.md)** - Documentation index

### Configuration Guide

Edit `config.yaml` to configure benchmarks across all four domains:

```yaml
# ğŸ“Š Data Science Benchmarks (349 total)
mle_competitions:
  - spaceship-titanic
  - house-prices-advanced-regression-techniques
  - digit-recognizer
  - nlp-getting-started
  # Add more Kaggle competitions...

# ğŸ“ Mathematical Modeling Benchmarks (1,296 total)
mathmodeling_competitions:
  - bwor-0
  - industry-5
  - mamo-easy-10-resource-allocation
  - mamo-complex-42-advanced-optimization
  - mamo-ode-15-population-model
  # Add more competitions...

# ğŸ”¬ Scientific Discovery Benchmarks (104 total)
science_competitions:
  - sciencebench-001-clintox-nn
  - sciencebench-002-mat-feature-select
  - sciencebench-003-predict-bulk-modulus
  - sciencebench-004-elk-new
  # Add more research problems...

# âš™ï¸ Engineering Benchmarks (102 total)
engineering_competitions:
  - industry-0
  - industry-10
  - industry-25
  - industry-50
  # Add more engineering problems...
```

### Advanced Usage

```python
from modeling.config import ModelingConfig, LLMConfig, WorkflowConfig
from modeling.workflows.factory import ScientificWorkflowFactory

# Configure workflow
config = ModelingConfig(
    llm=LLMConfig(provider='openai', model='gpt-4o-mini'),
    workflow=WorkflowConfig(name='scientific'),
    # ... other config
)

# Create workflow
factory = ScientificWorkflowFactory()
workflow = factory.create_workflow(config)

# Execute
result = await workflow.solve(task)
```

## ğŸ¤ Contributing

We welcome contributions! Areas for improvement across all four domains:

**Domain-Specific Contributions:**
- ğŸ“Š **Data Science**: Add more Kaggle competitions, especially multi-modal and complex tasks
- ğŸ“ **Mathematical Modeling**: Contribute optimization problems, nonlinear programming, mixed-integer problems
- ğŸ”¬ **Scientific Discovery**: Add computational biology, quantum chemistry, climate modeling problems
- âš™ï¸ **Engineering**: Contribute industrial case studies, control systems, robotics problems

**General Improvements:**
- ğŸ¨ **Multi-Modal Datasets**: Expand image, audio, video, and sensor data benchmarks
- ğŸ”¬ **Workflow Extensions**: Implement new discovery methods and ML techniques
- ğŸ› ï¸ **Tools Integration**: Connect external tools (MATLAB, Mathematica, specialized solvers)
- ğŸ“ **Documentation**: Improve guides, tutorials, and domain-specific examples
- ğŸ› **Bug Fixes**: Report and fix issues across any domain
- âš¡ **Performance**: Optimize solver speed, memory usage, and scalability

**How to Contribute:**

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

<span id='citation'/>

## ğŸŒŸ Citation

If you use DeepModeling in your research, please cite:

```bibtex
@software{deepmodeling2025,
  title={DeepModeling: Agentic LLM for Autonomous Problem Solving Across Data Science, Mathematical Modeling, Scientific Discovery, and Engineering},
  author={DeepModeling Team},
  year={2025},
  url={https://github.com/your-org/DeepModeling},
  note={Four-domain framework with 1,851 benchmark problems}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgements

**Benchmark Sources:**
- ğŸ“Š **Data Science**: MLE-Bench, Kaggle competition datasets
- ğŸ“ **Mathematical Modeling**: BWOR, IndustryOR, MaMo datasets (LP, ODE)
- ğŸ”¬ **Scientific Discovery**: DeepChem, Materials Project, computational science datasets
- âš™ï¸ **Engineering**: Industrial optimization case studies

**Infrastructure:**
- **LLM Providers**: OpenAI, Anthropic, and other model providers
- **Scientific Libraries**: SciPy, NumPy, scikit-learn, PyTorch, TensorFlow
- **Optimization Tools**: PuLP, CVXPY, Gurobi, specialized solvers

**Community:**
- Contributors across all four domains
- Users providing feedback and bug reports
- Research collaborators from industry and academia

## ğŸ“¬ Contact

For questions and support:
- ğŸ“§ Email: your-email@example.com
- ğŸ’¬ Issues: [GitHub Issues](https://github.com/your-org/DeepModeling/issues)
- ğŸ“– Docs: [Documentation](docs/)

---

<div align="center">
  <p>Made with â¤ï¸ by the DeepModeling Team</p>
  <p>â­ Star us on GitHub if you find this project helpful!</p>
</div>

<p align="right">(<a href="#readme-top">back to top</a>)</p>
